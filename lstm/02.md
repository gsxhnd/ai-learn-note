## How to Train LSTMs

本章节讲解了用于训练 LSTMs 的时间反向传播算法。完成本课后，你将会知道：

- 什么是时间的反向传播，以及它如何与多层感知器网络使用的反向传播训练算法相关联。
- 导致需要通过时间进行**截断反向传播（Truncated Backpropagation）**的动机，这是 LSTMs 深度学习中最广泛使用的变体。
- 考虑配置“经过时间截断的反向传播”以及研究和深度学习库中使用的规范配置的概念。
- 关于配置“经过时间截断的反向传播”以及研究和深度学习库中使用的规范配置的一种表示法。

## Backpropagation Training Algorithm

反向传播指的是两件事：

- 导数计算的数学方法及导数链式法则的应用。
- 更新网络权值以最小化误差的训练算法。

本课中使用的正是后一种对反向传播的理解。反向传播训练算法的目标是修改神经网络的权值，使网络输出相对于相应输入的期望输出的误差最小化。它是一种监督学习算法，允许网络根据特定的错误进行纠正。一般算法如下:

1. 提供一个训练输入模式，并通过网络传播它以获得输出。
2. 将预测输出与预期输出进行比较，并计算误差。
3. 计算误差对网络权值的导数。
4. 调整权重以使误差最小化。
5. 重复。

## Unrolling Recurrent Neural Networks
