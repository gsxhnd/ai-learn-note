# Models for Sequence Prediction

## Sequence Prediction

`LSTMs`通过学习一个函数（`f(...)`）来工作，该函数将输入序列值（`X`）映射为序列值（`y`）。

```
y(t) = f(X(t))
```

学习的映射函数是静态的，可以将其视为接受输入变量并使用内部变量的程序。 内部变量由网络维护的内部状态表示，并在输入序列的每个值上累积或累积。 可以使用不同数量的输入或输出定义静态映射功能。 了解这一重要细节是本课程的重点。

## Models for Sequence Prediction

在本节中，将回顾序列预测的 4 个主要模型。我们将使用以下术语：

- X：序列值输入；
- u：隐藏状态值；
- y：序列值输出；

每个模型都将使用术语、图片和 Keras 中的示例代码进行解释。 着重研究序列预测问题的不同类型如何映射到不同模型类型。 不要太着迷于 Keras 示例的细节，因为整章都致力于解释更复杂的模型类型。

### One-to-One Model

一个一对一模型（`f(…)`）对每个输入值（`X(t)`）产生一个输出（`y(t)`）。

![Figure 5.1: One-to-One Sequence Prediction Model.][lstm-05-01]

例如：

```
y(1) = f(X(1))
y(2) = f(X(2))
y(3) = f(X(3))
...
```

第一个时间步的内部状态为零；从这一点开始，内部状态（ internal state）在之前的时间步上累积。

![Figure 5.2: One-to-One Sequence Prediction Model Over Time.][lstm-05-02]

该模型适用于以一个时间步长为输入，预测一个时间步长的序列预测问题。例如:

- 预测时间序列中的下一个实际值。
- 预测句子中的下一个单词。

这种 LSTM 模型的效果很差，因为它无法跨输入或输出时间步学习。 该模型确实将所有压力施加在内部状态或内存上。 该模型的结果可以与具有输入或输出序列的模型进行对比，以查看跨时间步长的学习是否为预测增加了技巧。 我们可以通过在 Keras 中定义一个网络来实现这一点，该网络期望输入一个时间步长，并预测输出层的一个时间步长。

```python
model = Sequential()
model.add(LSTM(..., input_shape=(1, ...)))
model.add(Dense(1))
```

### One-to-Many Model

一个一对多的模型通过一个输入产生多个预测值。

```
y(1),y(2) = f(X(1))
```

考虑将时间分别计入输入和输出可能会有所帮助。

![Figure 5.3: One-to-Many Sequence Prediction Model.][lstm-05-03]

[lstm-05-01]: ../../.gitbook/assets/lstm_with_python/05-01.png
[lstm-05-02]: ../../.gitbook/assets/lstm_with_python/05-02.png
[lstm-05-03]: ../../.gitbook/assets/lstm_with_python/05-03.png
