# Models for Sequence Prediction

## Sequence Prediction

`LSTMs`通过学习一个函数（`f(...)`）来工作，该函数将输入序列值（`X`）映射为序列值（`y`）。

```
y(t) = f(X(t))
```

学习的映射函数是静态的，可以将其视为接受输入变量并使用内部变量的程序。 内部变量由网络维护的内部状态表示，并在输入序列的每个值上累积或累积。 可以使用不同数量的输入或输出定义静态映射功能。 了解这一重要细节是本课程的重点。

## Models for Sequence Prediction

在本节中，将回顾序列预测的4个主要模型。我们将使用以下术语：

- X：序列值输入；
- u：隐藏状态值；
- y：序列值输出；

每个模型都将使用术语、图片和Keras中的示例代码进行解释。 着重研究序列预测问题的不同类型如何映射到不同模型类型。 不要太着迷于Keras示例的细节，因为整章都致力于解释更复杂的模型类型。

### One-to-One Model

一个一对一模型（`f(…)`）对每个输入值（`X(t)`）产生一个输出（`y(t)`）。

![Figure 5.1: One-to-One Sequence Prediction Model.][lstm-05-01]

例如：

```
y(1) = f(X(1)) 
y(2) = f(X(2)) 
y(3) = f(X(3))
...
```

第一个时间步的内部状态为零；从这一点开始，内部状态（ internal state）在之前的时间步上累积。





[lstm-05-01]: ../../.gitbook/assets/lstm/05-01.png
