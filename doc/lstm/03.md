# How to Prepare Data for LSTM

## 准备数值数据

训练神经网络（如长-短期记忆递归神经网络）时，可能需要缩放序列预测问题的数据。当网络适合具有一系列值（例如 10 到 100 秒的数量）的无标度数据时，大的输入可能会减慢网络的学习和收敛速度，并且在某些情况下会阻止网络客观地学习您的问题。

您可能需要考虑两种类型的系列缩放：标准化和标准化。这两个都可以通过使用 Python 中的 scikit learn 机器学习库来实现。

### 归一化系列数据（Normalize Series Data）

归一化是对原始范围内的数据进行重新缩放，使所有值都在 0 和 1 的范围内。归一化要求您知道或能够准确估计最小和最大可观测值。您可以根据可用的数据估计这些值。如果序列呈上升或下降趋势，估计这些期望值可能会很困难，并且归一化可能不是解决问题的最佳方法。

如果要缩放的值超出最小值和最大值的范围，则结果值将不在 0 和 1 的范围内。您可以在进行预测之前检查这些观测值，并将其从数据集中删除，或将其限制为预定义的最大值或最小值。可以使用 scikit 学习对象 MinMaxScaler 规范化数据集。使用 MinMaxScaler 和其他缩放技术的良好实践如下：

- 使用可用的训练数据调整缩放器。对于归一化，这意味着训练数据将用于估计最小和最大可观测值。这是通过调用`fit()`函数来完成的。
- 将量表应用于培训数据。这意味着您可以使用规范化数据来训练模型。这是通过调用`transform()`函数来完成的。
- 将比例应用于未来的数据。这意味着您可以在将来准备新的数据，以便进行预测。

如果需要，可以反转变换。这对于将预测转换回其原始比例以进行报告或绘制非常有用。这可以通过调用`inverse_transform()`函数来完成。下面是一个将 10 个量的伪序列正规化的示例。scaler 对象要求以行和列的矩阵形式提供数据。加载的时间序列数据作为`Pandas Series`加载。

```python
from pandas import Series
from sklearn.preprocessing import MinMaxScaler
 define contrived series
data = [10.0, 20.0, 30.0, 40.0, 50.0, 60.0, 70.0, 80.0, 90.0, 100.0]
series = Series(data)
print(series)
 prepare data for normalization
values = series.values
values = values.reshape((len(values), 1))
 train the normalization
scaler = MinMaxScaler(feature_range=(0, 1))
scaler = scaler.fit(values)
print( Min: %f, Max: %f % (scaler.data_min_, scaler.data_max_))
 normalize the dataset and print
normalized = scaler.transform(values)
print(normalized)
 inverse transform and print
inversed = scaler.inverse_transform(normalized)
print(inversed)
```

运行示例将打印序列，打印从序列中估计的最小值和最大值，打印相同的规格化序列，然后使用逆变换将值打印回其原始比例。我们还可以看到，数据集的最小值和最大值分别为 10.0 和 100.0。

```shell
0 10.0
1 20.0
2 30.0
3 40.0
4 50.0
5 60.0
6 70.0
7 80.0
8 90.0
9 100.0

Min: 10.000000, Max: 100.000000

[[ 0. ]
[ 0.11111111]
[ 0.22222222]
[ 0.33333333]
[ 0.44444444]
[ 0.55555556]
[ 0.66666667]
[ 0.77777778]
[ 0.88888889]
[ 1. ]]

[[ 10.]
[ 20.]
[ 30.]
[ 40.]
[ 50.]
[ 60.]
[ 70.]
[ 80.]
[ 90.]
[ 100.]]

```

### 标准化系列数据（Standardize Series Data）

标准化数据集涉及重新调整值的分布，使观测值的平均值为 0，标准偏差为 1。这可以被认为是减去平均值或使数据居中。

与归一化一样，标准化也是有用的，甚至在某些机器学习算法中，当数据具有具有不同比例的输入值时，标准化也是必需的。标准化假设您的观测值符合高斯分布（bell 曲线），具有良好的平均值和标准偏差。如果不满足这一期望，您仍然可以将时间序列数据标准化，但可能无法获得可靠的结果。

标准化要求你知道或能够准确估计可观测值的平均值和标准差。您可以根据培训数据估计这些值。与最小值和最大值相比，数据集的平均值和标准差估计对新数据的鲁棒性更强。您可以使用 scikit 学习对象 StandardScaler 对数据集进行标准化。

```python
from pandas import Series
from sklearn.preprocessing import StandardScaler
from math import sqrt
 define contrived series
data = [1.0, 5.5, 9.0, 2.6, 8.8, 3.0, 4.1, 7.9, 6.3]
series = Series(data)
print(series)
 prepare data for normalization
values = series.values
values = values.reshape((len(values), 1))
 train the normalization
scaler = StandardScaler()
scaler = scaler.fit(values)
print( 'Mean: %f, StandardDeviation: %f' % (scaler.mean_, sqrt(scaler.var_)))
 normalize the dataset and print
standardized = scaler.transform(values)
print(standardized)
 inverse transform and print
inversed = scaler.inverse_transform(standardized)
print(inversed)
```

运行示例打印序列，打印序列估计的平均值和标准偏差，打印标准值，然后按原始比例打印值。我们可以看到，估计的平均值和标准差分别约为 5.3 和 2.7。

```shell
0    1.0
1    5.5
2    9.0
3    2.6
4    8.8
5    3.0
6    4.1
7    7.9
8    6.3
dtype: float64
Mean: 5.355556, StandardDeviation: 2.712568
[[-1.60569456]
 [ 0.05325007]
 [ 1.34354035]
 [-1.01584758]
 [ 1.26980948]
 [-0.86838584]
 [-0.46286604]
 [ 0.93802055]
 [ 0.34817357]]
[[1. ]
 [5.5]
 [9. ]
 [2.6]
 [8.8]
 [3. ]
 [4.1]
 [7.9]
 [6.3]]
```

### 缩放时的实际考虑

在缩放序列数据时有一些实际考虑。

- 估计系数。您可以从培训数据中估计系数（标准化的最小值和最大值，标准化的平均值和标准偏差）。检查这些第一次切割估计，并使用领域知识或领域专家帮助改进这些估计，以便它们在将来对所有数据都有用地进行更正。

- 保存系数。在将来，您将需要以与用于训练模型的数据完全相同的方式缩放新数据。保存用于存档的系数，并在以后进行预测时需要缩放新数据时加载它们。
- 数据分析。使用数据分析帮助您更好地理解数据。例如，一个简单的直方图可以帮助您快速了解数量的分布，看看标准化是否有意义。
- 缩放每个系列。如果问题有多个序列，请将每个序列视为单独的变量，然后分别缩放它们。这里，scale 指的是缩放过程的选择，例如标准化或标准化。
- 在正确的时间缩放。在正确的时间应用任何缩放变换都很重要。例如，如果您有一系列非平稳的量，则在第一次使数据平稳后缩放可能比较合适。将序列转换为监督学习问题后缩放该序列是不合适的，因为每个列都会被不同地处理，这是不正确的。
- 如有疑问，请按比例缩放。您可能需要重新调整输入和输出变量的大小。如果有疑问，至少要规范化数据。

## 准备分类数据

### 如何将分类数据转换为数值数据

这涉及两个步骤：

1. Integer Encoding.
2. One Hot Encoding.

#### Integer Encoding

作为第一步，为每个唯一的类别值分配一个整数值。例如，红色是 1，绿色是 2，蓝色是 3。这称为标签编码或整数编码，并且很容易可逆。对于某些变量，这可能就足够了。

整数值之间具有自然的有序关系，机器学习算法可以理解和利用这种关系。例如，上面的 place 示例这样的序数变量将是一个很好的示例，其中标签编码就足够了。

#### One Hot Encoding

对于不存在这种顺序关系的分类变量，整数编码是不够的。事实上，使用这种编码并允许模型假定类别之间的自然顺序可能会导致性能差或意外结果（类别之间的中间预测）。

在这种情况下，可以对整数表示应用 One Hot Encoding。这是删除整数编码变量并为每个唯一整数值添加新二进制变量的位置。在颜色变量示例中，有 3 个类别，因此需要 3 个二进制变量。颜色的二进制变量中放置 1 值，其他颜色的二进制变量中放置 0 值。例如：

```shell
red, green, blue
1, 	   0,    0
0, 	   1, 	 0
0, 	   0, 	 1
```

### One Hot Encode with scikit-learn

在本例中，我们假设您有以下 3 个标签的输出序列：cold、warm、Hot。10 个时间步骤的示例序列可以是：

```shel
cold、cold、warm、cold、hot、hot、warm、cold、warm、hot
```

这首先需要整数编码，例如 1、2、3。接下来是对整数进行一次热编码，得到一个包含 3 个值的二进制向量，例如[1，0，0]。序列提供了序列中每个可能值的至少一个示例。因此，我们可以使用自动方法定义标签到整数的映射和整数到二进制向量的映射。

在本例中，我们将使用 scikit 学习库中的编码器。具体地说，创建标签的整数编码的 LabelEncoder 和创建整数编码值的 one-hot encoding 的 onehotecoder。下面列出了完整的示例。

```PYTHON
from numpy import array
from numpy import argmax
from sklearn.preprocessing import LabelEncoder
from sklearn.preprocessing import OneHotEncoder
 define example
data = ['cold', 'cold', 'warm', 'cold', 'hot', 'hot', 'warm', 'cold', 'warm', 'hot']
values = array(data)
print(values)
 integer encode
label_encoder = LabelEncoder()
integer_encoded = label_encoder.fit_transform(values)
print(integer_encoded)
 binary encode
onehot_encoder = OneHotEncoder(sparse=False)
integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)
onehot_encoded = onehot_encoder.fit_transform(integer_encoded)
print(onehot_encoded)
 invert first example
inverted = label_encoder.inverse_transform([argmax(onehot_encoded[0, :])])
print(inverted)

```

运行示例首先打印标签序列。接下来是标签的整数编码，最后是一个热编码。训练数据包含所有可能的示例集，因此我们可以依赖整数和一个热编码转换来创建标签到编码的完整映射。

默认情况下，onehotecoder 类将返回更有效的稀疏编码。这可能不适合深度学习 lib 库等应用程序。在这种情况下，我们通过设置 sparse=False 参数来禁用 sparse 返回类型。如果我们在这个 3 值 1 热编码中接收到预测，我们可以很容易地将转换反转回原始标签。

首先，我们可以使用 argmax（）NumPy 函数来定位具有最大值的列的索引。然后可以将其输入 LabelEncoder，以计算返回到文本标签的反变换。这将在示例的末尾演示，其中第一个热编码示例的逆变换返回到标签值 cold。同样，请注意输入的格式是为了可读性。

```shell
['cold' 'cold' 'warm' 'cold' 'hot' 'hot' 'warm' 'cold' 'warm' 'hot']
[0 0 2 0 1 1 2 0 2 1]
[[1. 0. 0.]
 [1. 0. 0.]
 [0. 0. 1.]
 [1. 0. 0.]
 [0. 1. 0.]
 [0. 1. 0.]
 [0. 0. 1.]
 [1. 0. 0.]
 [0. 0. 1.]
 [0. 1. 0.]]
['cold']

```

## 准备不同长度的序列

深度学习库假设数据的矢量化表示。在可变长度序列预测问题中，这要求对数据进行转换，使每个序列具有相同的长度。这种矢量化允许代码为您选择的深度学习算法高效地批量执行矩阵操作。

### 序列填充(Sequence Padding)

在 Keras 深度学习 lib 库中，PAD 序列（）函数可以用来填充可变长度序列。默认的填充值是 0.0，这适用于大多数应用程序，不过可以通过 value 参数指定首选值来更改。例如：要应用于序列开始或结束的填充，称为前序列或后序列填充，可以由 padding 参数指定，如下所示。

#### 预序列填充（Pre-Sequence Padding）

Pre-Sequence Padding 是默认值（Padding=‘Pre’）。下面的示例演示如何使用 0 值预添加 3 个输入序列。

```python
from keras.preprocessing.sequence import pad_sequences
 define sequences
sequences = [
    [1, 2, 3, 4],
    [1, 2, 3],
    [1]
    ]
 pad sequence
padded = pad_sequences(sequences)
print(padded)
```

运行该示例将打印用零值预填充的 3 个序列。

```shell
[[1 2 3 4]
 [0 1 2 3]
 [0 0 0 1]]
```

#### 后置序列填充（Post-Sequence Padding）

填充也可以应用于序列的末尾，这可能更适合于某些问题域。可以通过将 padding 参数设置为 Post 来指定 Post 序列填充。

```python
from keras.preprocessing.sequence import pad_sequences
 define sequences
sequences = [
    [1, 2, 3, 4],
    [1, 2, 3],
    [1]
    ]
 pad sequence
padded = pad_sequences(sequences, padding='post')
print(padded)

```

运行示例将打印后置序列填充的相同序列

```shell
[[1 2 3 4]
 [1 2 3 0]
 [1 0 0 0]]
```

### 序列截断（Sequence Truncation）

序列的长度也可以修剪到所需的长度。序列所需的长度可以用 maxlen 参数指定为多个时间步。有两种方法可以截断序列：从序列的开始或结束删除时间步。

#### 预序列截断 Pre-Sequence Truncation

预序列截断默认的截断方法是从序列开始处删除时间步。这称为预序列截断。下面的示例将序列截断为所需的长度 2。

```python
from keras.preprocessing.sequence import pad_sequences
 define sequences
sequences = [
    [1, 2, 3, 4],
    [1, 2, 3],
    [1]
    ]

 truncate sequence
truncated= pad_sequences(sequences, maxlen=2)
print(truncated)
```

运行该示例将从第一个序列中删除前两个时间步骤，从第二个序列中删除第一个时间步骤，并填充最后一个序列。

```shell
[[3 4]
 [2 3]
 [0 1]]
```

#### 后序列截断（Post-Sequence Truncation）

序列也可以通过删除序列末尾的时间步长来进行修剪。这种方法可能更适合于一些问题领域。通过将截断参数从默认 pre 更改为 Post，可以配置 Post 序列截断，如下所示：

```python
from keras.preprocessing.sequence import pad_sequences
 define sequences
sequences = [
    [1, 2, 3, 4],
    [1, 2, 3],
    [1]
    ]

 truncate sequence
truncated= pad_sequences(sequences, maxlen=2, truncating='post')
print(truncated)
```

运行该示例将从第一个序列中删除最后两个时间步骤，从第二个序列中删除最后一个时间步骤，然后再次填充最后一个序列。

```shell
[[1 2]
 [1 2]
 [0 1]]
```

对于何时填充和何时截断不同长度的输入序列，没有经验法则。例如，为了提高效率，在情感分析中截断很长的文本可能是有意义的，或者填充短文本并让模型学习忽略或显式屏蔽零输入值以确保没有数据丢失也是有意义的。我建议为序列预测问题测试一组不同的表示，并对那些产生最佳模型技巧的表示进行加倍。

## 序列预测作为监督学习

序列预测问题，必须重新构造为监督学习问题。也就是说，数据必须从一个序列转换为一对输入和输出对。

### Sequence vs Supervised Learning

在我们开始之前，让我们花点时间更好地理解原始输入序列和监督学习数据的形式。考虑一个按时间索引排序的数字序列。
这可以看作是有序值的列表或列。例如：

```shell
0
1
2
3
4
5
6
7
8
9
```

有监督学习问题由输入模式（X）和输出模式（y）组成，因此算法可以学习如何从输入模式预测输出模式。
例如：

```shell
X, y
1, 2
2, 3
3, 4
4, 5
5, 6
6, 7
7, 8
8, 9
```

这将表示序列的 1-滞后变换，使得必须在给定序列的前一时间步的情况下预测当前时间步。

### Pandas `shift()` Function

帮助将时间序列数据转换为监督学习问题的关键函数是 Pandas shift（）函数。给定一个数据帧，shift（）函数可用于创建向前推（前面添加了一行 NaN 值）或向后拉（后面添加了一行 NaN 值）的列的副本。

这是以监督学习格式为时间序列数据集创建滞后观测列和预测观测列所需的行为。让我们看看 shift（）函数的一些实际例子。我们可以将模拟时间序列数据集定义为 10 个数字的序列，在这种情况下，数据帧中的单个列如下所示：

```python
from pandas import DataFrame
 define the sequence
df = DataFrame()
df['t'] = [x for x in range(10)]
print(df)
```

运行此示例将打印包含每个观测的行索引的时间序列数据。

```shell
  t
0 0
1 1
2 2
3 3
4 4
5 5
6 6
7 7
8 8
9 9
```

我们可以通过在顶部插入一个新行，将所有观测值一步一步地向下移动。
因为新行没有数据，所以我们可以使用 NaN 来表示没有数据。shift 函数可以为我们这样做，我们可以将这个移位列插入到原始序列的旁边。

```python
from pandas import DataFrame
 define the sequence
df = DataFrame()
df['t'] = [x for x in range(10)]
 shift forward
df['t-1'] = df['t'].shift(1)
print(df)
```

运行该示例会在数据集中显示两列。第一个是原始观测和一个新的移位列。我们可以看到，将序列向前移动一个时间步会产生一个原始的有监督学习问题，尽管 X 和 y 的顺序不对。忽略行标签的列。由于 NaN 值的原因，第一行必须被丢弃。第二行在第二列（input 或 X）中显示 0.0 的输入值，在第一列（output 或 y）中显示 1 的值。

```shell
  t t-1
0 0 NaN
1 1 0.0
2 2 1.0
3 3 2.0
4 4 3.0
5 5 4.0
6 6 5.0
7 7 6.0
8 8 7.0
9 9 8.0
```

如果可以以 2、3 和更多的移位重复这个过程，可以创建长输入序列（X），用于预测输出值（y）。

移位运算符也可以接受负整数值。这样可以通过在末尾插入新行来将观察结果向上拉。下面是一个例子：

```python
from pandas import DataFrame
 define the sequence
df = DataFrame()
df[ t ] = [x for x in range(10)]
 shift forward
df[ t-1 ] = df[ t ].shift(-1)
print(df)

```

运行该示例将显示一个新列，最后一个值是 NaN 值。我们可以看到 forecast 列可以作为输入（X），第二列作为输出值（y）。即 0 的输入值可用于预测 1 的输出值。

```shell
  t t+1
0 0 1.0
1 1 2.0
2 2 3.0
3 3 4.0
4 4 5.0
5 5 6.0
6 6 7.0
7 7 8.0
8 8 9.0
9 9 NaN
```

从技术上讲，在时间序列预测术语中，当前时间（t）和未来时间（t+1，t+n）是预测时间，过去的观测（t-1，t-n）用来进行预测。可以看到如何使用正移位和负移位从一个有监督学习问题的输入和输出模式序列的时间序列中创建新的数据帧。

这不仅允许经典的 X->y 预测，而且允许输入和输出都可以是序列的 X->y 预测。此外，移位函数也适用于所谓的多元时间序列问题。也就是说，有多个观测值（例如温度和压力），而不是一组时间序列的观测值。时间序列中的所有变量都可以向前或向后移动，以创建多变量输入和输出序列。

## 进一步阅读

### Numeric Scaling APIs

1. MinMaxScaler API in scikit-learn.
   <https://goo.gl/H3qHJU>

2. StandardScaler API in scikit-learn.
   <https://goo.gl/cA4vQi>

3. Should I normalize/standardize/rescale the data? Neural Nets FAQ.
   <ftp://ftp.sas.com/pub/neural/FAQ2.html#A_std>

### Categorical Encoding APIs

1. LabelEncoder API in scikit-learn.
   <https://goo.gl/Y2bn3T>
2. OneHotEncoder API in scikit-learn.
   <https://goo.gl/ynDMHN>
3. NumPy argmax() API.
   <https://docs.scipy.org/doc/numpy/reference/generated/numpy.argmax.html>

### Varied Length Sequence APIs

1. pad sequences() API in Keras.
   <https://keras.io/preprocessing/sequence/>

### Supervised Learning APIs

1. shift() function API in Pandas.<https://goo.gl/N3M3nG>

## Summary

1. 如何缩放数字数据以及如何转换分类数据。
2. 如何填充和截断不同长度的输入序列。
3. 如何将输入序列转化为有监督学习问题。
